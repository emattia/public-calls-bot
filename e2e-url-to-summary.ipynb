{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "905f7235-9565-463d-86c2-7c8e03d24e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from IPython.display import JSON\n",
    "\n",
    "# Poorly named, custom stuff\n",
    "from wrappers import ytdlp_extract_audio, transcribe, summarize_key_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44b26889-5d01-401f-9f94-83b144c0f8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = os.path.join(os.getcwd(), 'data')\n",
    "AUDIO_OUTPUT = os.path.join(os.getcwd(), DATA_ROOT, 'audio')\n",
    "SUMMARY_OUTPUT = os.path.join(os.getcwd(), DATA_ROOT, 'summaries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6af68c82-2fa2-4cd0-b830-f726f24e6b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.youtube.com/watch?v=WZzKt-TC9WM' # Explainer video in the docs\n",
    "out_dir = os.path.join(os.getcwd(), DATA_ROOT, 'argumentation-io')\n",
    "json_schema_file = os.path.join(out_dir, 'schema.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ddd9d2-9cd5-4b97-bd76-9201ee9df72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = {\n",
    "    '$schema': 'https://json-schema.org/draft/2020-12/schema',\n",
    "    '$id': 'https://example.com/product.schema.json',\n",
    "    'title': 'Product explainer summarizer',\n",
    "    'description': 'A product explainer explainer.',\n",
    "    'type': 'object',\n",
    "    'properties': {\n",
    "        'productName': {'description': 'The name of a product', 'type': 'string'},\n",
    "        'targetUser': {\n",
    "            'description': 'Description of target users of a product.',\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'segments': {\n",
    "                    'description': \"Explain the archetype user's job and characteristics.\",\n",
    "                    'items': {'type': 'string'},\n",
    "                    'minItems': 1,\n",
    "                    'uniqueItems': True\n",
    "                },\n",
    "                'needs': {\n",
    "                    'description': \"Explaining the archetype user's reasons for using the product.\",\n",
    "                    'items': {'type': 'string'},\n",
    "                    'minItems': 1,\n",
    "                    'uniqueItems': True\n",
    "                }\n",
    "            },\n",
    "            'required': ['segments', 'needs']\n",
    "        },\n",
    "        'productFunction': {\n",
    "            'description': 'What does this product do?',\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'features': {\n",
    "                    'description': 'List of features provided by the product.',\n",
    "                    'type': 'array',\n",
    "                    'items': {\n",
    "                        'type': 'object',\n",
    "                        'properties': {\n",
    "                            'featureName': {\n",
    "                                'description': 'Name of the feature.',\n",
    "                                'type': 'string'\n",
    "                            },\n",
    "                            'userExperience': {\n",
    "                                'description': 'Description of the user experience for this feature.',\n",
    "                                'type': 'string'\n",
    "                            }\n",
    "                        },\n",
    "                        'required': ['featureName', 'userExperience']\n",
    "                    },\n",
    "                    'minItems': 1\n",
    "                },\n",
    "                'implementation': {\n",
    "                    'description': 'Details on how the product is implemented.',\n",
    "                    'type': 'object',\n",
    "                    'properties': {\n",
    "                        'developerTools': {\n",
    "                            'description': 'Developer tools used for implementation.',\n",
    "                            'type': 'array',\n",
    "                            'items': {'type': 'string'},\n",
    "                            'minItems': 1,\n",
    "                            'uniqueItems': True\n",
    "                        },\n",
    "                        'platforms': {\n",
    "                            'description': 'Platforms on which the product is available.',\n",
    "                            'type': 'array',\n",
    "                            'items': {'type': 'string'},\n",
    "                            'minItems': 1,\n",
    "                            'uniqueItems': True\n",
    "                        }\n",
    "                    },\n",
    "                    'required': ['developerTools', 'platforms']\n",
    "                }\n",
    "            },\n",
    "            'required': ['features', 'implementation']\n",
    "        }\n",
    "    },\n",
    "    'required': ['productName', 'targetUser', 'productFunction']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "289ae683-8ece-4a12-bf20-81f3b820915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_schema_file, 'w') as f:\n",
    "    f.write(json.dumps(json_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1afb3980-1b5f-42b4-9bc3-a6878d2c3a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting audio from https://www.youtube.com/watch?v=WZzKt-TC9WM... Converting .mp3 to .wav 16-bit.\n"
     ]
    }
   ],
   "source": [
    "audio_filename = ytdlp_extract_audio(url, out_dir=AUDIO_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd4701ad-17ee-4b40-9da9-8959dc0ad30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing /Users/eddie/Dev/Alignment/public-calls-bot/data/audio/20230724_Argumentation.io Explainer.wav...\n"
     ]
    }
   ],
   "source": [
    "txt_filename = transcribe(\n",
    "    audio_filename, \n",
    "    out_dir=out_dir,\n",
    "    path_to_whisper_cpp=os.path.join(os.getcwd(), 'whisper.cpp')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8788c9e5-ec84-4913-a038-5fa0ab2d82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"You are an experienced and savvy product designer with many years of experience as a full-stack engineer.\n",
    "This is a transcript from a product explainer video.\n",
    "\n",
    "%s\n",
    "\n",
    "Summarize the content in JSON. Do not repeat featureNames, segments, needs, or any other JSON array substructures. \n",
    "Highlight the key features of the app, who is likely the target user, and include relevant implementation and user experience details.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75cf7e24-c0c9-464e-adac-fa1b4ac4b202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing /Users/eddie/Dev/Alignment/public-calls-bot/data/argumentation-io/20230724_Argumentation.io Explainer.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log start\n",
      "main: build = 2933 (6aade19e)\n",
      "main: built with Apple clang version 15.0.0 (clang-1500.3.9.4) for arm64-apple-darwin23.5.0\n",
      "main: seed  = 1716141339\n",
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /Users/eddie/Dev/Alignment/public-calls-bot/llama.cpp/models/llama-2-7b.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
      "ggml_backend_metal_log_allocated_size: allocated buffer, size =  3820.94 MiB, ( 3821.00 / 21845.34)\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:      Metal buffer size =  3820.93 MiB\n",
      "llm_load_tensors:        CPU buffer size =    70.31 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: n_batch    = 2048\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M1 Max\n",
      "ggml_metal_init: picking default device: Apple M1 Max\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/Users/eddie/Dev/Alignment/public-calls-bot/llama.cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M1 Max\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction support   = true\n",
      "ggml_metal_init: simdgroup matrix mul. support = true\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 22906.50 MB\n",
      "llama_kv_cache_init:      Metal KV buffer size =  1024.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:      Metal compute buffer size =   164.00 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    12.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "\n",
      "system_info: n_threads = 8 / 10 | AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "sampling: \n",
      "\trepeat_last_n = 64, repeat_penalty = 1.000, frequency_penalty = 0.000, presence_penalty = 0.000\n",
      "\ttop_k = 40, tfs_z = 1.000, top_p = 0.950, min_p = 0.050, typical_p = 1.000, temp = 0.800\n",
      "\tmirostat = 0, mirostat_lr = 0.100, mirostat_ent = 5.000\n",
      "sampling order: \n",
      "CFG -> Penalties -> top_k -> tfs_z -> typical_p -> top_p -> min_p -> temperature \n",
      "generate: n_ctx = 2048, n_batch = 2048, n_predict = 2448, n_keep = 1\n",
      "\n",
      "\n",
      " [end of text]\n",
      "\n",
      "llama_print_timings:        load time =     436.42 ms\n",
      "llama_print_timings:      sample time =    1158.20 ms /   245 runs   (    4.73 ms per token,   211.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3960.67 ms /  1417 tokens (    2.80 ms per token,   357.77 tokens per second)\n",
      "llama_print_timings:        eval time =    7050.05 ms /   244 runs   (   28.89 ms per token,    34.61 tokens per second)\n",
      "llama_print_timings:       total time =   12445.57 ms /  1661 tokens\n",
      "ggml_metal_free: deallocating\n",
      "Log end\n"
     ]
    }
   ],
   "source": [
    "prompt_file, summary_txt_file, summary_json_file  = summarize_key_features(\n",
    "    transcript_filepath = txt_filename, \n",
    "    out_dir = out_dir, \n",
    "    json_schema_file = json_schema_file,\n",
    "    prompt_template = prompt_template,\n",
    "    path_to_llama_cpp = os.path.join(os.getcwd(), 'llama.cpp')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35d144da-e208-4f1e-a229-7a41dba4ec61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "productFunction": {
        "features": [
         {
          "featureName": "Basic Features",
          "userExperience": "Navigate to main contention, group box, inference box, reasons, copremaces, and objections using key commands or the mouse. Drag and drop boxes to move them and move them back again. Use the main menu button to navigate to a how-to page that covers everything in this video and more. <br>"
         },
         {
          "featureName": "Tabs",
          "userExperience": "In the lower left-hand corner of the screen, click on the workspace outside of your map, and drag the mouse around to zoom in and out. Click on the tab button to navigate to a how-to page that covers everything in this video and more."
         }
        ],
        "implementation": {
         "developerTools": [
          "Slate"
         ],
         "platforms": [
          "web"
         ]
        }
       },
       "productName": "argumentation.io",
       "targetUser": {
        "needs": [
         "learning",
         "productivity"
        ],
        "segments": [
         "students",
         "teachers"
        ]
       }
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(summary_json_file, 'r') as f:\n",
    "    summary_dict = json.loads(f.read())\n",
    "JSON(summary_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
